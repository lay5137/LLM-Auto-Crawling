name: Auto Crawl & Vector DB

on:
  schedule:
    - cron: '0 0 * * *'   # 매일 자정 실행
  workflow_dispatch:

jobs:
  crawl_vector:
    runs-on: ubuntu-latest
    steps:
      #  레포 체크아웃
      - name: Checkout repo
        uses: actions/checkout@v4

      #  Python 설치
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      #  uv 설치 후 dependencies 설치
      - name: Install dependencies (fast with uv)
        run: |
          # uv 설치
          pip install --upgrade pip
          pip install uv
          
          # 핵심 패키지 설치
          uv pip install --system selenium chromedriver-autoinstaller openpyxl pandas openai
          
          # langchain 및 관련 패키지 설치
          uv pip install --system \
            langchain==0.0.27 \
            langchain-core==1.0.3 \
            langchain-openai==0.3.34 \
            langchain-huggingface==1.0.1 \
            langchain-text-splitters==1.0.0 \
            langchain-community==0.4.1 \
            langchain-chroma==0.2.6 \
            chromadb==1.1.0 \
            sentence-transformers==5.1.1 \
            pydantic==2.11.9 || pip install pydantic==2.11.9

      #  크롤러 실행
      - name: Run crawler
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: python crawler.py

      #  Markdown → TXT 변환
      - name: Convert MD → TXT
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: python txt_transfer.py

      #  TXT → Chroma 벡터 DB 생성
      - name: Build Vector DB
        run: python vector_store.py

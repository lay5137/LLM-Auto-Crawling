import os
import re
import time
import openpyxl
from urllib.parse import urljoin
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import chromedriver_autoinstaller
import subprocess


def sanitize_filename(name):
    return re.sub(r'[\\/*?:"<>|]', "_", name)


# âœ… í¬ë¡¬ë“œë¼ì´ë²„ ì„¤ì¹˜ ë° ì„¤ì •
chromedriver_autoinstaller.install()
chrome_options = Options()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
driver = webdriver.Chrome(service=Service(), options=chrome_options)
driver.implicitly_wait(5)

# âœ… ì €ì¥ ê²½ë¡œ (GitHub ì €ì¥ì†Œ ë‚´ë¶€ í´ë”)
save_base = './result_files'
os.makedirs(save_base, exist_ok=True)

excel_path = os.path.join(save_base, "crawl_result.xlsx")

# âœ… ì—‘ì…€ íŒŒì¼ ì´ˆê¸°í™” or ë¶ˆëŸ¬ì˜¤ê¸° (ğŸ”¹ URL ì—´ ì¶”ê°€)
if not os.path.exists(excel_path):
    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "ê²Œì‹œê¸€ ëª©ë¡"
    ws.append(["ê²Œì‹œê¸€ ì œëª©", "ì‘ì„±ì", "ì‘ì„±ì¼", "URL"])  # âœ… URL ì—´ ì¶”ê°€
    wb.save(excel_path)
    existing_keys = set()
else:
    wb = openpyxl.load_workbook(excel_path)
    ws = wb.active
    existing_keys = set()
    for row in ws.iter_rows(min_row=2, values_only=True):
        title, writer, date, *_ = row  # âœ… URLì€ ë¬´ì‹œí•˜ê³  ê¸°ì¡´ í‚¤ ìœ ì§€
        if title and date:
            existing_keys.add(f"{title.strip()}_{date.strip()}")
    print(f"âœ… ê¸°ì¡´ ê²Œì‹œê¸€ {len(existing_keys)}ê±´ ë¡œë“œ ì™„ë£Œ.")


# âœ… URL í¬í•¨í•˜ë„ë¡ ìˆ˜ì •
def append_to_excel(title, writer, date, url, excel_path):
    wb = openpyxl.load_workbook(excel_path)
    ws = wb.active
    ws.append([title, writer, date, url])  # âœ… URL ì €ì¥ ì¶”ê°€
    wb.save(excel_path)


# ===============================
# ê³µì£¼ëŒ€ SWì¤‘ì‹¬ëŒ€í•™ ê³µì§€ì‚¬í•­ í¬ë¡¤ëŸ¬
# ===============================
base_url = "https://swknu.kongju.ac.kr"
board_url = f"{base_url}/community/notice.do?&pn=6"
max_pages = 1  # ìµœëŒ€ í˜ì´ì§€ ìˆ˜

print(f"\n========== ğŸ” ê³µì£¼ëŒ€ SWì¤‘ì‹¬ëŒ€í•™ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ ì‹œì‘ ==========")

driver.get(board_url)
page_num = 4

while True:
    print(f"\nğŸ“„ {page_num}í˜ì´ì§€ ì²˜ë¦¬ ì¤‘... ({driver.current_url})")
    items = driver.find_elements(By.CSS_SELECTOR, ".list-photo .item")

    if not items:
        print("âŒ ê²Œì‹œê¸€ í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, ì¢…ë£Œ.")
        break

    for idx, item in enumerate(items, start=1):
        try:
            link_elem = item.find_element(By.CSS_SELECTOR, "a[href*='noticedetail.do']")
            title = item.find_element(By.CSS_SELECTOR, ".title").text.strip()
            post_url = urljoin(base_url, link_elem.get_attribute("href"))
            info_elems = item.find_elements(By.CSS_SELECTOR, ".post-info span")

            writer = info_elems[0].text.strip() if len(info_elems) > 0 else "ì •ë³´ ì—†ìŒ"
            date = info_elems[1].text.strip() if len(info_elems) > 1 else "ì •ë³´ ì—†ìŒ"

            key = f"{title}_{date}"
            if key in existing_keys:
                print(f"â© ({idx}) {title} ({date}) â†’ ì´ë¯¸ ì¡´ì¬, ê±´ë„ˆëœ€")
                continue

            print(f"ğŸ“° ({idx}) {title} ({date}) â†’ ìƒˆ ê²Œì‹œê¸€ ì²˜ë¦¬ ì¤‘...")

            driver.get(post_url)
            time.sleep(1)

            try:
                content_elem = driver.find_element(By.CSS_SELECTOR, ".view-note")
                content = content_elem.text.strip()
            except:
                content = "ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            file_links = []
            try:
                file_elems = driver.find_elements(By.CSS_SELECTOR, "div.post-file ul li a")
                for f in file_elems:
                    fname = f.text.strip()
                    furl = urljoin(base_url, f.get_attribute("href"))
                    if fname and fname != "ë¯¸ë¦¬ë³´ê¸°":
                        file_links.append((fname, furl))
            except:
                pass

            safe_title = sanitize_filename(title)[:80]
            file_path = os.path.join(save_base, f"{safe_title}.md")

            markdown = f"""# {title}

**ì‘ì„±ì:** {writer}  
**ì‘ì„±ì¼:** {date}  

---

## ë³¸ë¬¸
{content}

---

## ì²¨ë¶€íŒŒì¼
"""
            if file_links:
                for fname, furl in file_links:
                    markdown += f"- [{fname}]({furl})\n"
            else:
                markdown += "ì²¨ë¶€íŒŒì¼ ì—†ìŒ\n"

            with open(file_path, "w", encoding="utf-8") as f:
                f.write(markdown)

            # âœ… URL ì¸ì ì¶”ê°€
            append_to_excel(title, writer, date, post_url, excel_path)
            existing_keys.add(key)
            print(f"âœ… ì €ì¥ ì™„ë£Œ â†’ {file_path}")

            driver.back()
            time.sleep(1)

        except Exception as e:
            print(f"â— ê²Œì‹œê¸€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue

    try:
        next_page = driver.find_element(By.CSS_SELECTOR, f"a[href*='pn={page_num+1}']")
        driver.get(next_page.get_attribute("href"))
        page_num += 1
        if page_num > max_pages:
            print(f"ğŸ”’ ìµœëŒ€ {max_pages}í˜ì´ì§€ ë„ë‹¬ â†’ ì¢…ë£Œ")
            break
    except:
        print("ğŸ“„ ë‹¤ìŒ í˜ì´ì§€ ì—†ìŒ â†’ ì¢…ë£Œ")
        break

driver.quit()
print("\nâœ… ëª¨ë“  í¬ë¡¤ë§ ì™„ë£Œ!")

# âœ… GitHubì— ìë™ í‘¸ì‹œ
subprocess.run(["git", "config", "--global", "user.email", "github-actions@github.com"])
subprocess.run(["git", "config", "--global", "user.name", "github-actions"])
subprocess.run(["git", "add", "."])
subprocess.run(["git", "commit", "-m", "Auto update crawl results"])
subprocess.run(["git", "push"])
